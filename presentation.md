Assumptions:
- You have Gemini/Open AI subscription and API key
- You have AM Best account to scrape ratings individually

Files structure
- ambest/ -> holds HTML files of AM Best results
- prompts/ -> holds textual prompt where we inject our data and pass to LLM
- scraped_data/ -> data our module scrapes are held in this directory
- venv/ -> local environment. Holds all the dependencies required for module
- am_best_scraper.py -> the module that scrapes AM Best ratings
- scrape_insurance.py -> main module. It scrapes data from websites give in websites.txt file and stores
                        them in scraped_data. It also has the main business logic
- websites.txt -> It holds all the insurance websites we want to scrape
- output.txt -> Output generated in a TXT file
- output.pdf -> Output generated in a PDF file

Constraints/Limitations:
- Data scarcity: Not all data is available on their website
- AM Best: Requires separate scraping and it gives access only after login
- Some data points are behind paywall - requires separate subscription
- Need subscription of a newer openai model

To improve AI result:
- Need data from several sources (paid and free)
- Require better AI model (paid - openai)
- More data the better! -> accuracy increases!

Result:
- We writing data in a txt file and a pdf file
- pdf file is autogenerated
- pdf file is styled for readability

